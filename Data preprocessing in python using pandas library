import pandas as pd

# Load the dataset
dataset = pd.read_csv('your_dataset.csv')

# Handling missing values
dataset = dataset.fillna(0)  # Replace missing values with zeros
# Or use dataset.dropna() to remove rows with missing values

# Feature scaling
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaled_features = scaler.fit_transform(dataset[['feature1', 'feature2', 'feature3']])

# Handling categorical variables
encoded_data = pd.get_dummies(dataset['categorical_column'])

# Splitting the dataset into features and target variable
X = dataset.drop('target_column', axis=1)
y = dataset['target_column']

# Splitting the dataset into training and testing sets
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Data normalization
from sklearn.preprocessing import MinMaxScaler

scaler = MinMaxScaler()
normalized_features = scaler.fit_transform(dataset[['feature1', 'feature2', 'feature3']])
